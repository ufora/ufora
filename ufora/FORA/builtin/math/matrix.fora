/***************************************************************************
   Copyright 2015 Ufora Inc.

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
****************************************************************************/
#Markdown("""
### matrix

#### Description

Library for matrices and linear algebra.

""");

Matrix: 
#Markdown("""
### Matrix

#### Description

A class for matrices and linear algebra. 

Matrices are currently implemented in terms of `math.Tensor`s having rank two.
As such, they may have column-major data layout, row-major, or neither.

Matrix arithmetic and linear algebra are currently implemented by BLAS and LAPACK. As such,
these operations are only possible on "small" matrices (around 50 MB). If 
one attemps to use one of these BLAS or LAPACK dependent routines on a matrix having too large 
of a data vector, something bad will happen. 

Since matrices are ultimately implemented in terms of Vectors, and FORA vectors can be 
quite large (and distributed), we have plans on implementing arithmetic on such matrices.
""")
class 
	{
	operator new
		(filters.IsVector(data))
			{
			Matrix(data, (size(data), 1));
			}
		(filters.IsVector(data), `column)
			{
			Matrix(data);
			}
		(filters.IsVector(data), `row)
			{
			Matrix(data, (1, size(data)))
			};

#Markdown(
"""#### Description

The underlying implementation of a matrix.
""")
	member matrixImpl_;

	static checkDim_:
		fun(dim)
			{
			if (size(dim) != 2)
				throw "`dim` argument must have size 2, instead got: " + String(size(dim))
			};

	static FromTensor:
#Markdown(
"""#### Usage

	math.Matrix(tensorInstance)

#### Description

Construct a `Matrix` from an instance of `math.Tensor`, `tensorInstance`.

Note that `tensorInstance` must have rank two.

#### Arguments

* `tensorInstance` -- Tensor. An instance of class math.Tensor.

#### Examples

	math.Matrix.FromTensor(math.Tensor(Vector.range(4.0), (2,2)))

""")
	fun (tensor)
		{
		checkDim_(tensor.dim);
		
		createInstance(cls, matrixImpl_: tensor)
		};


#Markdown(
"""#### Usage

	math.Matrix(data, dim)

#### Description

Construct a matrix from a `Vector` `data` having dimensions `dim`.

Equivalent to calling ``math.Matrix(data, dim, `column)``.

#### Arguments

* `data` -- Vector. Containing the elements of the matrix.
* `dim` -- Tuple of Integers. Giving the dimension of the matrix.

#### Examples

	math.Matrix([1,2,3,4], (2,2))
	math.Matrix(Vector.range(100.0), (10,10))

""")
	static operator ()(data, dim)
		{
		checkDim_(dim);

		FromTensor(Tensor(data, dim, `column, 0))
		};

#Markdown(
"""#### Usage

	math.Matrix(data, dim, strides)

#### Description 

Construct a matrix having data vector `data`, dimensions `dim`, and strides `strides`.

Equivalent to calling `math.Matrix(data, dim, strides, 0)`.

#### Arguments

* `data` -- a Vector containing the elements of the matrix
* `dim` -- a Tuple of Integers giving the dimension of the matrix.
* `strides` -- a Tuple of Integers describing how elements of the matrix are to be read from data, or the value `column, indicating that the elements of the matrix should be read from data in column-major order, or the value `row, indicating that the elements of the matrix should be read from data in row-major order.

#### Examples

	math.Matrix(Vector.range(8.0), (2,2), (1,2))

""")
	static operator ()(data, dim, strides)
		{
		checkDim_(dim);

		FromTensor(Tensor(data, dim, strides, 0))
		};

#Markdown(
"""#### Usage

	math.Matrix(data, dim, strides, offset)

#### Description

Construct a matrix having data vector `data`, dimensions `dim`, strides `strides`, and offset `offset`.

Equivalent to calling `math.Matrix.FromTensor(math.Tensor(data, dim, strides, offset))`.

#### Arguments

* `data` -- a Vector containing the elements of the vector.
* `dim` -- Tuple of int, giving the dimensions of the vector.
* `strides` -- Tuple of int, describing how the elements of the vector are to be read from data, or the value `column, indicating that the elements of the vector should be read from data in column-major order, or the value `row, indicating that the elements of the vector should be read from data in row-major order.
* `offset` -- an integer which, together with strides, tells how to read off elements in the vector from the data vector.

#### Examples

	math.Matrix(Vector.range(1200.0), (2,30), (2, 4), 10)

""")
	static operator ()(data, dim, strides, offset)
		{
		checkDim_(dim);

		createInstance(cls, matrixImpl_: Tensor(data, dim, strides, offset))
		};

#Markdown(
"""#### Usage

	A.dim

#### Description

Returns the dimensions of the matrix `A`.

#### Examples

	math.Matrix(Vector.range(10000000), (20,300)).dim == (20, 300)

""")
	dim: matrixImpl_.dim;

    operator match (tag if tag is Matrix) { (dim,) };

    operator match (Visualizable _) {
        try {
            let grid = builtin.drawGrid(
                fun(rowObj, column) {
                    rowObj[column]
                    },
                fun(row) { self[row] },
                self.dim[0],
                self.dim[1]
                );

            let spacing = "    ";
            (#Markdown(spacing + grid.replace("\n", "\n" + spacing)),)
            }
        catch (e) {
            return (String(self),)
            }
        };

eltType_: 
#Markdown("""#### Usage

    A.eltType_

#### Description

Returns the 'element type' of `A` for the purposes of BLAS/LAPACK operations.
This returns `Float64` if the data vector of `A` is anything but a homogeneous 
vector of `Float64` or `Float32`, since we coerce such matrices to `Float64` 
before passing to BLAS/LAPACK. If `A`'s data vector is a homogeneous vector 
of `Float64` or `Float32`, then we return `Float64` and `Float32`, respectively.

""")
	try { 
        let computedType = matrixImpl_.homogeneousElementType;

        match (computedType) with
            (Float64 or Float32) { computedType} 

		} catch (...) { Float64 };

	...(`size) { 
		dim[0] * dim[1];
		};

	convert (String) {
		let tr = "Matrix(dim=" + String(dim) + ", ";
		tr = tr + self.matrixImpl_.dataStringRep_(size(tr)) + ")";
		tr
	};

	isSquare:
#Markdown(
"""#### Usage

	A.isSquare()

#### Description

Computes whether or not `A` is a square matrix, ie `A.dim[0] == A.dim[1]`.

#### Examples

	math.Matrix(Vector.range(12), (3,4)).isSquare() is false;
	math.Matrix(Vector.range(16), (4,4)).isSquare() is true;

""")
	fun() {
		dim[0] == dim[1]
		};

    inv: inverse;

	inverse:
#Markdown(
"""#### Usage

	m.inverse()

or
    
    m.inv();

#### Description

Computes the `inverse` of a square matrix `m`, if it exists, or throws an exception 
if it doesn't.

#### Examples

	math.Matrix([2.0, 1.0, 1.0, 1.0], (2,2)).inverse() == math.Matrix([1.0, -1.0, -1.0, 2.0], (2,2))

""")
	fun ()
		{
		if (isSquare())
			{
			if (self.implIsColumnMajor_)
				{
				return Matrix(
					blasWrappers.getri(
						dim[0],
						columnMajorData()
						),
					dim
					);
				}
			else {
				 return Matrix(
					 blasWrappers.getri(
						 dim[0],
						 rowMajorData()
						 ),
					 dim
					 ).transpose();
				 }
			}
		else
			throw "Can only invert square, column-major matrices of Float32 or Float64"
		};

	pseudoinverse:
#Markdown(
"""#### Usage

	A.pseudoinverse(withRank:=false, thresh:=nothing)
    A.pinv(withRank:=false, thresh:=nothing)

#### Description

Computes the Moore-Penrose pseudoinverse of a matrix `A` using the singular value 
decomposition of `A` and including all "large" singular values of `A`. Here, large 
means all singular values of `A` greater than `thresh` times the largest singular 
value_of_A. In the default case, `thresh = nothing`, `thresh` gets reset to 

    math.machinePrecision(A.eltType_) * builtin.max(A.dim)

If `withRank` is `false`, we just return an estimate of `A`'s pseudoinverse. If 
`withRank` is `true`, we return a tuple `(pinv:pinv, rank:rank)` where `pinv` is the 
(estimated) pseudoinverse of `A` and `rank` is the estimated rank of `A` using `thresh` 
(that is, the number of singular values of `A` greater than `thresh` times the largest 
singular value of `A`).

#### Examples

    let m = math.Matrix([1,2,3, 3,2,1, 1,1,1], (3,3))
    m.pseudoinverse()
    m.pinv()
    m.pseudoinverse(withRank:true)
    m.pinv(withRank:true)

""")
	fun(withRank:=false, thresh:=nothing)
		{
		let (X, isTransposed) = 
			if (implIsColumnMajor_) { (columnMajorData(), false) }
			else { (rowMajorData(), true) }
			;
			
		let (m, n) = 
			if (isTransposed) { (dim[1], dim[0]) }
			else { (dim[0], dim[1]) }
			;

		let (singVals, U, Vt) = blasWrappers.gesvd('A', 'A', m, n, X)

		if (thresh is nothing)
			{
			thresh = machinePrecision(eltType_) * (n >>> m);
			}
		thresh = thresh * builtin.max(singVals);

		let rank = 0;
		let sigmaPseudoInvData = []; // we don't really need to build up this matrix
		for i in sequence(m) {
			let singVal_i = if (i <= m <<< n - 1) { singVals[i] } else { eltType_(0) };
			for j in sequence(n) {
				if (i == j and singVal_i > thresh) {
					rank = rank + 1;
					sigmaPseudoInvData = sigmaPseudoInvData :: (1.0 / singVal_i);
					}
				else {
					sigmaPseudoInvData = sigmaPseudoInvData :: eltType_(0)
					}
				}
			}			

		let pinv_ = math.Matrix(Vt, (n, n)).transpose() *
				  	math.Matrix(sigmaPseudoInvData, (n, m)) * 
						math.Matrix(U, (m, m)).transpose();
			
		if (isTransposed) pinv_ = pinv_.transpose()
		
		if (withRank) return (pinv:pinv_, rank:rank);

		return pinv_;
		};

pinv: pseudoinverse;

	rank:
#Markdown(
"""#### Usage

	A.rank()
    A.rank(tol)

#### Description

Estimate the rank of a matrix `A`. The first form returns the number of singular values 
of `A` which are greater than the default tolerance, 

    max(A.dim) * A.norm() * 2.22e-16 //for Float64 A
    max(A.dim) * A.norm() * 1.192e-7 //for Float32 A

(recall that `A.norm()` is the two-norm, ie, the largest singular value of `A`).

The second form returns the number of singular values of `A` greater than `tol`.
""")
	fun
	() 
		{
		let singVals = singularValues();

		let thresh = machinePrecision(eltType_) * (dim[0] >>> dim[1]) * 
				builtin.max(singVals);

		rank_(thresh, singVals)
		}
	(thresh)
		{
		rank_(thresh, singularValues())
		};



static rank_:
	fun(thresh, singVals) {
		let tr = 0;

		for val in singVals {
			if (val > thresh)
				tr = tr + 1
			}
		
		tr
		};

	max:
#Markdown(
"""#### Usage

	A.max()

#### Description

Returns the largest element in a matrix `A`.
""")
	fun()
		{
		if (implIsColumnMajor_)
			return builtin.max(columnMajorData())
		
		return builtin.max(rowMajorData())
		}
		;

	dataStringRep_:
#Markdown(
"""#### Usage

	m.dataStringRep_(n)

#### Description 

Returns a string representation of the elements in the matrix `m`, using `n` to limit
 the number of characters in the returned string.

#### Arguments

* `n` -- Integer

#### Examples 

	math.Matrix(Vector.range(4), (2,2)).dataStringRep_(0) == "[[0.0, 2.0], [1.0, 3.0]]"
	math.Matrix(Vecor.range(4), (2,2)).dataStringRep_(101) == "..."

""")
	 fun(charsSoFar) 
		{
		if (charsSoFar > 100) return "..."
		let tr = "["
		for ix in sequence(dim[0]) {
			if (size(tr) + charsSoFar > 100)
				return tr + " ...]"
			
			if (ix > 0)
				tr = tr + ", "
			if (size(dim) > 1)
				tr = tr + self[ix].dataStringRep_(size(tr) + charsSoFar)
			else
				tr = tr + String(self[ix])
		}
		tr + "]"
		};
	
	implIsColumnMajor_: matrixImpl_.implIsColumnMajor_;

	implIsRowMajor_: matrixImpl_.implIsRowMajor_;
		
    T: transpose;

	transpose:
#Markdown(
"""#### Usage

	m.transpose()

or

    m.T()

#### Description

Returns the matrix transpose of `m`.

#### Examples

	math.Matrix([0,1,2,3,4,5], (2,3)).transpose() == math.Matrix([0,2,4,1,3,5], (3,2))

""")
	fun()
		{
		createInstance(cls, matrixImpl_: matrixImpl_.transpose())
		};
	
	columnMajorData:
#Markdown(
"""#### Usage

	A.columnMajorData()

#### Description

Given a matrix `A`, returns a vector containing the elements of `A` 
listed in column-major order.

More precisely, suppose that `A.dim == (m, n)`. Then for each `0 <= i < m` and 
`0 <= j < n`, we have `A.columnMajorData()[i + j * m] == A[i][j]`

#### Examples

	math.Matrix(Vector.range(6), (2,3), `row).columnMajorData() == [0,3,1,4,2,5]

""")
	fun()
		{
		matrixImpl_.columnMajorData()
		};


#Markdown(
"""#### Usage

	m.rowMajorData()

#### Description

Given a `math.Matrix` instance `m`, this returns a vector `v` satisfying

	math.Matrix(v, m.dim, `row) == m

#### Examples

	math.Matrix([1,2,3,4], (2,2)).rowMajorData() == [1,3,2,4]
	math.Matrix([1,2,3,4], (2,2), `row).rowMajorData() == [1,2,3,4]
	math.Matrix([1,2,3,4], (2,2), (0,1)).rowMajorData() == [1, 2, 1, 2]

""")
	rowMajorData:
	fun()
		{
		matrixImpl_.rowMajorData()
		};

#Markdown(
"""#### Usage

	m[]
	m[*slices, r]

#### Description

Slices a matrix `m`. 

This is implemented by slicing the underlying `Tensor` reprsenting `m`, so in the 
case of a single argument, this returns a `math.Tensor` index which describes a 
given row of `m`. In the case of two arguments, say `x[i, j]`, this returns 
`m[i][j]`. In the case of no arguments, this returns the underlying `Tensor` 
representing `m`. Finally, in the case of 3 or more arguments, we get an exception.

#### Examples

	let t = math.Matrix(Vector.range(8), (2,4));
	t[] == math.Tensor(Vector.range(8), (2,4));
	t[0] == math.Tensor([0,2,4,6], (4,));
	t[1] == math.Tensor([1,3,5,7], (4,));
	t[0,1] == 2;

""")
	operator []() { 
		matrixImpl_[] 
		};
	operator [](*slices, r) {
		matrixImpl_[*slices, r]
		};

#Markdown(
"""#### Usage

	m1 == m2

#### Description

The equality operator for matrices.

Two matrices are considered equal if they have the same dimensions and each 
pair of corresponding elements is the same.

""")	
	operator ==(Matrix(...) other) 
		{
		matrixImpl_ == other.matrixImpl_;
		};

#Markdown(
"""#### Usage

	m1 + m2

#### Description

Computes the matrix sum of matrices `m1` and `m2`.

#### Examples

	let m1 = math.Matrix([1.0,2.0,3.0,4.0], (2,2));
	let m2 = math.Matrix([5.0,6.0,7.0,8.0], (2,2));

	m1 + m2 == math.Matrix([6.0,8.0,10.0,12.0], (2,2));	

""")
	operator +( Matrix(...) x ) 
		{
		if (dim != x.dim)
			throw "Can't add Matrix of dimension " + String(dim)
			+ " to Matrix of dimension " + String(x.dim)
		;
		
		let (A, B, layout) = 
			if (implIsColumnMajor_ and x.implIsColumnMajor_) { 
				(columnMajorData(), x.columnMajorData(), `column) 
				}
			else { //one or more of them is represented in rowmajor form, or
				   //neither row nor col, so the following will do:
				(rowMajorData(), x.rowMajorData(), `row)
				}				
			;

		return Matrix(
			blasWrappers.axpy(1.0, A, B),
			dim, layout
			);
		}
	(nothing)
		{
		return self;
		};


#Markdown(
"""#### Usage

	m1 - m2

#### Description

Computes the matrix difference of `m1` and `m2`.

#### Examples

	let m1 = math.Matrix([1.0,2.0,3.0,4.0], (2,2));
	let m2 = math.Matrix([1.0,2.0,3.0,4.0], (2,2), (2,1));
	
	m1 - m2 == math.Matrix([0.0, -1.0, 1.0, 0.0], (2,2));

""")
	operator -( Matrix(...) x ) 
		{
		if (dim != x.dim)
			throw "Can't subtract a matrix of dimension " + String(x.dim)
			+ " from a matrix of dimension " + String(dim)
		;
		
		let (A, B, layout) = 
			if (implIsColumnMajor_ and x.implIsColumnMajor_) { 
				(columnMajorData(), x.columnMajorData(), `column) 
				}
			else { //one or more of them is represented in rowmajor form, or
				   //neither row nor col, so the following will do:
				(rowMajorData(), x.rowMajorData(), `row)
				}				
			;					

		return Matrix(
			blasWrappers.axpy(-1.0, B, A),
				dim, layout
			);
		};

    operator /(x)
        {
        self * (x ** -1)
        };

#Markdown(
"""#### Usage

	m1 * m2

#### Description

Computes the matrix product of `m1` with `m2`.

#### Examples

	let m1 = math.Matrix([1.0,2.0,3.0,4.0], (2,2));
	let m2 = math.Matrix([5.0,6.0,7.0,8.0], (2,2));
	
	m1 * m2 == math.Matrix([23,34,31,46], (2,2));

	let m1 = math.Matrix([1.0,1.0,1.0,1.0,1.0,1.0], (2,3));
	let m2 = math.Matrix([1.0,1.0,1.0], (3,1));
	
	m1 * m2 == math.Matrix ([3.0, 3.0], (2,1));

""")
	operator *( Matrix(...) x ) 
		{
		if (dim[1] != x.dim[0])
			throw "can't multiply a matrix with dimension " + String(dim) + 
                " with a matrix of dimension " + String(x.dim)

		let (transA, lda, A) = 
			if (implIsColumnMajor_) 
				{ (false, dim[0], columnMajorData()) }
			else //`self` is either row-major, or neither column nor row-major  
				{ (`transpose, dim[1], rowMajorData()) }
			;

		let (transB, ldb, B) = 
			if (implIsColumnMajor_) 
				{ (false, x.dim[0], x.columnMajorData()) }
			else //`x` is either row-major, or neither column nor row-major  
				{ (`transpose, x.dim[1], x.rowMajorData()) }
			;

		return Matrix(
			blasWrappers.gemm(
				transA,
				transB,
				dim[0],
				x.dim[1],
				x.dim[0],
				1.0,
				A,
				lda,
				B,
				ldb,
				0.0,
				nothing
				),
			(dim[0], x.dim[1])
			);
		};			

#Markdown(
"""#### Usage

	m ** n

#### Description

Computes the repeated product `m * m * ... * m`, `n`-times.

#### Arguments

* `n` - Integer

#### Examples

	math.Matrix([1.0, 0.0, 0.0, 2.0], (2,2)) ** 10 == math.Matrix([1.0, 0.0, 0.0, 1024.0], (2,2))

""")
	operator **
	({Int64} or {Int32} or {Int8} or {UInt64} or {UInt32} or {UInt8} n) 
		{ 
		if (n < 0) return inverse() ** (-n);
		
		if (n == 0) return identity (dim[0]);

		if (n % 2)
			{
			let m = self ** ((n - 1) / 2);
			return self * m * m
			}
		else
			{
			let m = self ** (n / 2);
			return m * m;
			}
		}; 

	trace:
#Markdown(
"""#### Usage

	m.trace()

#### Description

Returns the trace of matrix `m`.

#### Examples

	math.Matrix([1.0, 3.3, 5.5, 9.0], (2, 2)).trace() == 10.0

""")
	fun()
		{
		if (!isSquare())
			throw "can only take the trace of a square matrix"
		let tr = nothing;
		for i in sequence (dim[0]) tr = tr + self[i][i];

		tr;
		};

	det:
#Markdown(
"""#### Usage 

	m.det()

#### Description

Computes the determinant of a square matrix `m`.

#### Examples

	math.Matrix([2.0, 1.0, 1.0, 1.0], (2, 2)).det() == 1.0;
	math.Matrix([0.0, 0.0, 0.0, 0.0], (2, 2)).det() == 0.0;

""")
	fun()
		{
		let n = dim[0];
		
		let (LU, ipiv) = 
			try {
				let data = 
    				if (self.implIsColumnMajor_) {
  	    				columnMajorData();
		    			}
			    	else {
				    	rowMajorData();
					    }
				    ;
				let eltType = nothing;
				(eltType, data) = blasWrappers.eltTypeAndFloatifyIfNecessary(data);

				blasWrappers.getrf(n, n, data);
			} catch (e) {
				if (e == "matrix A was singular")
					return 0.0

				throw e;
				}
		
		let signFlag = true;
		for i in sequence(n) {
			if (ipiv[i] != i + 1) //fortran arrays are 1-based.
				signFlag = !signFlag;
			}
		
		let det = 1.0;
		
		for i in sequence(n)
			{
			det = det * LU[i * (n + 1)];
			}
		
		if (signFlag)
			return det;
		
		return -det;
		}
		;				
	
    nrow: dim[0];
    ncol: dim[1];

    applyWithIndexes: applyWithIndices;

    static vstack:
#Markdown(
"""
#### Usage

    math.Matrix.vstack(m1, m2)

#### Description

Produces the "vertical stack" of matrices `m1` and `m2`. For matrices with the same
number of columns, this is equivalent to writing

    math.Matrix(
        m1.rowMajorData() + m2.rowMajorData(),
        (m1.nrow + m2.nrow, m1.ncol),
        `row
        )

For matrices with different number of columns, this expression throws.
"""
)
        fun(m1, m2)
            {
            if (m1.ncol != m2.ncol)
                throw "arguments must have the same number of columns"

            math.Matrix(
                m1.rowMajorData() + m2.rowMajorData(),
                (m1.nrow + m2.nrow, m1.ncol),
                `row
                );
            };

    static hstack:
#Markdown(
"""
#### Usage

    math.Matrix.hstack(m1, m2)

#### Description

Produces the "horizontal stack" of matrices `m1` and `m2`. For matrices with the same 
number of rows, this is equivalent to writing

    math.Matrix(
        m1.columnMajorData() + m2.columnMajorData(),
        (m1.nrow, m1.ncol + m2.ncol)
        )

For matrices with different number of rows, this expression throws.
"""
)
        fun(m1, m2)
            {
            if (m1.nrow != m2.nrow)
                throw "arguments must have the same number of rows"
 
            math.Matrix(
                m1.columnMajorData() + m2.columnMajorData(),
                (m1.nrow, m1.ncol + m2.ncol)
                );
            };

    applyWithIndices:
#Markdown(
"""
#### Usage

    m.applyWithIndices(applyFun)

or

    m.applyWithIndexes(applyFun)

#### Description

Given a function of three variables `applyFun` and matrix `m`, produces a new matrix
with the same dimensions as `m`, whose `(row, col)` entry is 

    applyFun(m[row, col], row, col)

"""
)
    fun
    (applyFun)
        {
        if (implIsRowMajor_)
           return math.Matrix(
               rowMajorData().applyWithIndex(
                   fun(elt, ix) { applyFun(elt,	ix / ncol, ix % ncol) }
                   ),
               (nrow, ncol),
               `row
               )
        else 
           return math.Matrix(
               columnMajorData().applyWithIndex(
                   fun(elt, ix) { applyFun(elt, ix % nrow, ix / nrow) }
                   ),
               (nrow, ncol)
               )
        };

    operator ~~(f) {
        self.apply(f)
        };

	apply:
#Markdown(
"""#### Usage

	m.apply(f)

#### Description

Applies a function `f` to each entry of a matrix `m`, producing a new matrix with those values.

Equivalent to calling `math.Matrix(m.matrixImpl_.apply(f))`.

""")
	fun(applierFun)
		{
		createInstance(cls, matrixImpl_: matrixImpl_.apply(applierFun))
		};

	`hidden
	multiply:
#Markdown(
"""#### Usage

	m1.multiply(m2)

#### Description

multiply 'self' and 'x' as matrices.  

Doesn't do any checking on bounds sizes. Callers should do that	first.

If the output is zero dimensional, returns a number.
""")
	fun(x) 
		{
		if (size(dim) == 0 or size(x.dim) == 0)
			throw "Invalid dimensions for multiplyInto."
		
		if (size(dim) == 1 and size(x.dim) == 1)
			{
			let res = nothing;
			
			for ix in sequence(dim[0]) {
				res = res + self[ix] * x[ix]
			};
			
			return res
			}
		else
			if (size(dim) > size(x.dim))
			{
			throw "not implemented"
			}
		else
			{
			throw "not implemented"
			}
		};

#Markdown(
"""#### Usage

	m * x

#### Description

Computes the scalar multiple of `Matrix` `m` by `x`.

#### Examples

	math.Matrix(Vector.range(8.0), (2,2)) * 2.0 == math.Matrix(Vector.range(16.0), (2,2), (2,4))

""")
	operator *(x) 
		{
		if (implIsColumnMajor_)
			return Matrix(
				blasWrappers.scal(
					size(self),
					x,
					columnMajorData()
					), 
				dim
				);
				
		return Matrix(
			blasWrappers.scal(
				size(self),
				x, 
				rowMajorData()
				),
			dim, `row
			);
		};	
	
#Markdown(
"""#### Usage

	x * m

#### Description

Computes the scalar mutiple of `Matrix` `m` by `x`.

#### Examples

	2 * math.Tensor(Vector.range(8.0), (2,2)) == math.Tensor(Vector.range(16.0), (2,2), (2,4))

""")
	reverse operator *(x)
		{
		self * x	
		};
#Markdown(
"""#### Usage

	-m

#### Description

Computes the scalar multiple of `Matrix` `m` by `-1.0`.

""")
	left operator -()
		{
		-1.0 * self
		};
	
	lu:
#Markdown(
"""#### Usage

	A.lu()

#### Description

Computes the LU decomposition of `A` with partial pivoting. 

Given some matrix `A` as input, returns a tuple `(P, L, U)` such that `A = P * L * U`, 
where `U` is an upper triangular matrix with unit entries along the diagonal, 
`L` is a strictly lower triangular matrix, and `P` is a permutation matrix.

#### Examples

	let m = math.Matrix(Vector.range(4.0), (2,2), `row);
	let (P, L, U) = m.lu();

Then 

	P == math.Matrix([0.0, 1.0, 1.0, 0.0], (2,2))
	L == math.Matrix([1.0, 0.0, 0.0, 1.0], (2,2))
	U == math.Matrix([2.0, 0.0, 3.0, 1.0], (2,2)).

""")
	fun()
		{ 
		decomposition.lu(self) 
		};

	svd: 
#Markdown(
"""#### Usage

	A.svd()

#### Description

Computes the singular value decomposition of a matrix `A`.

Given some `m`-by-`n` matrix `A` as, `A.svd()` is a tuple `(U, Sigma, Vt)` such that
`A = U * Sigma * Vt` (approximately), where `Sigma` is an `m`-by-`n` matrix which 
is zero except possibly its `min(m, n)` diagonal elements, `U` is an `m`-by-`m` 
orthogonal matrix, and VT is an `n`-by-`n` orthogonal matrix.  The diagonal elements 
of `Sigma` are the singular values of `A`; they are real and non-negative, and are returned in 
descending order. 

#### Examples

	let m = math.Matrix(Vector.range(5.0)[1,], (2,2));
	let (U, Sigma, Vt) = m.svd();

""")
	fun()
		{ 
		decomposition.svd(self) 
		};

	cholesky: 
#Markdown(
"""#### Usage

	A.cholesky(uplo = `lower)

#### Description

Computes the Cholesky decomposition of a matrix.

Given a real matrix `A`, let `sym(A, uplo)` denote the symmetric matrix 
determined by the upper triangle of `A` if ``uplo == `upper``, or the 
symmetric matrix determined by the lower triangle of `A` if 
``uplo == `lower``. `A.cholesky(uplo)` computes the Cholesky 
decomposition of `sym(A, uplo)`, returning the matrix `L` such that 
`sym(A, uplo) = L * L.transpose()`. If the symmetric matrix inspected 
is not positive definite, this function raises an exception (note though 
that the mathematical Cholesky decomposition exists if the matrix is 
just positive _semi_-definite).

#### Arguments

* `uplo` -- Symbol, either `` `lower`` or `` `upper``

""")
	fun(uplo = `lower)
		{ 
		decomposition.cholesky(self, uplo) 
		};

	qr:
#Markdown( 
"""#### Usage

	A.qr()

#### Description

Computes the QR decomposition of a matrix.

Given a real matrix `A`, `A.qr()` is a tuple `(Q, R)` where `A = Q * R` (approximately), the
QR-Decomposition of `A`.  
""")
	fun()
		{ 
		decomposition.qr(self) 
		};

	eigenvalues:
#Markdown(
"""#### Usage

	A.eigenvalues()

#### Description

Computes the eigenvalues of a real matrix.

Given a real `n` x `n` matrix `A`, returns a length-two tuple `(wr, wi)`
encoding the `n` complex eigenvalues of the matrix `A`. Here, `wr` and 
`wi` are length-`n` vectors of `Float64`'s (or `Float32`'s). For each 
`0 <= ix <= n - 1`, the pair `(wr[ix], wi[ix])` gives the real
and imaginary parts, respectfully, of an eigenvalue of `A`.

#### Examples

	let A = math.Matrix([0.0, 1.0, -1.0, 0.0], (2,2));
 
Then

	A.eigenvalues() == ([0.0, 0.0], [1.0, -1.0])

#### Potential pitfall:

Beware of repeated eigenvalues! Since this is a numeric routine, it may return more 
eigenvalues than actually exist for `A` (counted without algebraic multiplicity). 

""")
	fun() { eigen.eigenvalues(self) };

eigenvectors:
#Markdown(
"""#### Usage 

	A.eigenvectors()

#### Description

Computes the eigenvalues and a corresponding set of eigenvectors of a real matrix.

Given an `n` x `n` real matrix `A`, `A.eigenvectors()` is a triple `(wr, wi, v)` 
of vectors representing the eigenvalues and eigenvectors of the matrix `A`. 

As in `A.eigenvalues`, for each `0 <= ix <= n - 1`, the pair `(wr[ix], wi[ix])` gives
the real and imaginary parts, respectfully, of an eigenvalue of `A`. If `wi[ix] == 0.0`, ie 
we have a purely real eigenvalue, then a corresponding eigenvector is given by 

	math.Matrix(v[ix, ix + n], (n, 1))

In the case of complex eigenvalues (corresponding to indices `0 <= ix < n - 1` such 
that `wi[ix] != 0.0`), pulling out corresponding eigenvectors is slightly more complicated. 
Complex eigenvalues (for real matrices) always come in complex-conjugate pairs, and these 
pairs appear adjacently in `v`. We assign pairs of eigenvalues by corresponding index, 
going from low index to high, such that no index appears in more than one pair.
 
For example, if our eigenvalues, listed with index are 

	(1,0) [i = 0], (1, 1) [i = 1], (1, -1) [i = 2], (1, 1) [i = 3], (1, -1) [i = 4]

Then we have two complex-conjugate pairs, one occuring at indices 1 and 2, and the other 
at indices 3 and 4 (indices 2 and 3 are not considered a pair).

Suppose that `ix` and `ix + 1` are indices corresponding to a complex-conjugate 
eigenvalue pair in the above sense and that `wi[ix] != 0.0`. Although we currently 
can't perform arithmetic with complex matrices, an eigenvector 
corresponding to the eigenvalue `(wr[ix], wi[ix])` is given, morally speaking, by

	math.Matrix(v[ix, ix + n], (n, 1)) + math.Complex.i * math.Matrix(v[ix + n, ix + 2 * n]. 

An eigenvector corresponding to the eigenvalue `(wr[ix + 1], wi[ix + 1])` is given, 
morally speaking, by

	math.Matrix(v[ix, ix + n], (n, 1)) - math.Complex.i * math.Matrix(v[ix + n, ix + 2 * n].	 

#### Potential pitfall:

Beware of repeated eigenvalues! Since this is a numeric routine, it may return more 
eigenvalues than actually exist for `A` (counted without algebraic multiplicity). 
In this case, the dimension of the eigenspaces will be greater than it should be.
Even in the case of repeated eigenvalues (as reported by the function), 
the dimension of the eigenspaces may be greater than their true, mathematically-defined values.

For instance, consider the matrix `let A = math.Matrix([1.0, 0.0, 1.0, 1.0], (2,2))`. This
matrix truly has only one eigenvalue, `1`, with algebraic multiplicity `1`. `A.eigenvectors()`
will agree with the fact that there is only one eigenvalue, but will claim that the dimension
of the corresponding eigenspace is two. Note though, that the two eigenvectors in this case are 
very close, reflecting the fact that the true eigenspace is one-dimensional.

""")
	fun() { eigen.eigenvectors(self) };

leftEigenvectors:
#Markdown(
"""#### Usage

	A.leftEigenvectors()

#### Description

Computes the eigenvalues and a set of corresponding left-eigenvectors of a matrix.

Given an `n` x `n` real matrix `A`, `A.leftEigenvectors()` returns a triple `(wr, wi, v)` 
representing the eigenvalues and left-eigenvectors of `A`. 

As in `A.eigenvalues()` and `A.eigenvectors()`, for each `0 <= ix <= n - 1`, the pair
`(wr[ix], wi[ix])` gives the real and imaginary parts, respectfully, of a eigenvalue 
of `A`. If `wi[ix] == 0.0`, ie we have a purely real eigenvalue, then a corresponding 
left-eigenvector is given by 

	math.Matrix(v[2 * ix, 2 * ix + n], (1, n))

Suppose that `ix` and `ix + 1` are indices corresponding to a complex-conjugate 
eigenvalue pair in the above sense and that `wi[ix] != 0.0` (in the sense
 described in the `A.eigenvectors()` docstring), although we can't currently 
perform arithmetic on complex matrices, a corresponding left-eigenvector for 
this eigenvalue is given, morally, by 

	math.Matrix(v[ix, ix + n], (1, n)) + math.Complex.i * math.Matrix(v[ix + n, ix + 2 * n], (1, n))

A left-eigenvector for the eigenvalue `(wr[ix + 1], wi[ix + 1])` is given, morally speaking, by

	math.Matrix(v[ix, ix + n], (1, n)) - math.Complex.i * math.Matrix(v[ix + n, ix + 2 * n], (1, n))

#### Potential pitfall:

Beware of repeated eigenvalues! See the note in the docstring for `A.eigenvectors()`.

""")
	fun() { eigen.leftEigenvectors(self) };

leftAndRightEigenvectors:
#Markdown(
"""#### Usage

	A.leftAndRightEigenvectors()

#### Description

Computes the eigenvalues and a set of corresponding left-eigenvectors, and a set of 
corresponding right-eigenvectors.

Given an `n` x `n` real matrix `A`, returns a four-tuple `(wr, wi, vl, vr)` representing 
the eigenvalues, eigenvectors, and left-eigenvectors of `A`. For each 
`0 <= ix <= n - 1`, the pair `(wr[ix], wi[ix])` represents the real and imaginary 
parts, respectfully, of an eigenvalue of `A`. If `wi[ix] == 0.0`, ie we have a 
purely real eigenvalue, then a corresponding left-eigenvector is given by

	math.Matrix(vl[2 * ix, 2 * ix + n], (1, n))

and a corresponding right-eigenvector is given by 

	math.Matrix(vr[2 * ix, 2 * ix + n], (n, 1)).

Suppose that `ix` and `ix + 1` are indices corresponding to a complex-conjugate 
eigenvalue pair in the above sense and that `wi[ix] != 0.0` (in the sense
 described in the `A.eigenvectors()` docstring). Although we can't 
currently perform arithmetic on complex matrices, a corresponding left-eigenvector for 
the eigenvalue is given, morally, by

	math.Matrix(vl[ix, ix + n], (1, n)) + math.Complex.i * math.Matrix(vl[ix + n, ix + 2 * n], (1, n))

and a corresponding right-eigenvector is given, morally, by

	math.Matrix(vr[ix, ix + n], (n, 1)) + math.Complex.i * math.Matrix(vr[ix + n, ix + 2 * n], (n, 1)).

A left-eigenvector corresponding to the eigenvalue `(wr[ix + 1], wi[ix + 1])`, of is given, 
morally, by 

	math.Matrix(vl[ix, ix + n], (1, n)) - math.Complex.i * math.Matrix(vl[ix + n, ix + 2 * n], (1, n))

and a corresponding right-eigenvector is given, morally, by

	math.Matrix(vr[ix, ix + n], (n, 1)) - math.Complex.i * math.Matrix(vr[ix + n, ix + 2 * n], (n, 1)).

### Potential pitfall 

Beware of repeated eigenvalues -- see the comments in `A.eigenvalues()`.

""")
	fun() 
		{ 
		eigen.leftAndRightEigenvectors(self) 
		};

	symeigenval: 
#Markdown(
"""#### Usage

	A.symeigenval(uplo = `lower)

#### Description

Computes the eigenvalues of a real symmetric matrix.

Given a real matrix `A`, let `sym(A, uplo)` denote the symmetric matrix 
determined by the upper triangle of `A` (including diagonal entries) if 
``uplo == `upper``, or the symmetric matrix determined by the lower 
triangle of `A` if ``uplo == `lower``. The call `A.symeigenval(uplo)` returns a 
vector containing the `n` eigenvalues, not necessarily distinct, of 
the matrix `sym(A, uplo)`. 
""")
	fun(uplo = `lower)
		{ 
		eigen.symeigenval(self, uplo) 
		};

	symeigenpair: 
#Markdown(
"""#### Usage

	A.symeigenpair(uplo = `lower)

#### Description

Computes the eigenvalues and an orthonormal set of corresponding eigenvectors.

Given a real matrix `A`, let `sym(A, uplo)` denote the symmetric matrix 
determined by the upper triangle of `A` (including diagonal entires) if 
``uplo == `upper``, or the symmetric matrix determined by the lower 
triangle of `A` if ``uplo == `lower``. `A.symeigenpair(uplo)` returns 
a vector containing the `n` tuple pairs of eigenvalues and eigenvectors 
of the matrix `A`.  The first element in the tuple is the eigenvector, 
the second, the corresponding eigenvalue. 
""")
	fun(uplo = `lower)
		{ 
		eigen.symeigenpair(self, uplo) 
		};

	singularValues: 
#Markdown(
"""#### Usage

	A.singularValues()

#### Description

Computes the singular values of a matrix.

Given an `m`-by-`n` matrix `A` as input, `A.singularValues()` returns a vector `S` 
containing the `min(m, n)` singular values of `A`. `S` stores the singular values of 
`A`, sorted so that `S[i] >= S[i + 1]`.
""")
	fun()
		{ 
		functions.singularValues(self) 
		};

	norm: 
#Markdown(
"""#### Usage

	m.norm(p = `two)

#### Description

Compute a matrix norm.

Compute the 1-norm, 2-norm, inf-norm or frobenius-norm of a matrix `m` over R. If the 
data for `m` is stored in row major format, it must resample the data vector for 
calculating the frobenius norm. Callers can designate the norm by passing one of 
the symbols `` `infinite``, `` `frobenius``, `` `one``, and `` `two`` as the argument `p`; 
by default ``p == `two``.
	
The various norms compute:

	`one -- max_{j} ( sum_{i} abs( m_{i,j} ) )
	`two -- sigmaMax(m), where sigmaMax(m) is the largest singular value of m 
	`infinite -- max_{i} ( sum_{j} abs ( m_{i,j} ) )
	`frobenius -- sqrt( trace(m.transpose() * m) ) 

""")
	fun(p = `two)
		{ 
		functions.norm(self, p) 
		};

	cond: 
#Markdown(
"""#### Usage

	m.cond(p = `two)

#### Description

Compute the condition number of a matrix according to some matrix norm.

Computes the condition number of `m` with respect to the 1-norm, 2-norm, inf-norm 
or frobenius-norm. Callers can designate the norm with
respect to which the condition number is to be calculated by passing one of the 
symbols `` `infinite``, `` `frobenius``, `` `one``, and `` `two`` as the argument `p`; 
by default ``p == `two``.
	
The various norms compute:

	`one -- max_{j} ( sum_{i} abs( m_{i,j} ) )
	`two -- sigmaMax(m), where sigmaMax(m) is the largest singular value of m 
	`infinite -- max_{i} ( sum_{j} abs ( m_{i,j} ) )
	`frobenius -- sqrt( trace(m.transpose() * m) ) 

""")
	fun(p = `two)
		{ 
		functions.cond(self, p) 
		};

	diagonalElements:
#Markdown(
"""#### Usage

    m.diagonalElements()

#### Description

Return the diagonal elements of matrix `m` as a vector. If `m` is not square,
the returned vector is of size `min(nRows,nColumns)`.

""")
		fun()
		{
		let diagonals = [];
		for i in sequence( min(self.dim) )
			{
			diagonals = diagonals :: matrixImpl_[i,i];
			}

		diagonals;
		};

	static linsolv: functions.linsolv;

	static identity:
#Markdown(
"""
#### Usage

    math.Matrix.identity(n)

#### Description

Creates an `n`-by-`n` identity matrix (of `Float64`).
""") 
	fun(n) 
		{ 
		diagonal(n)
		};

	static diagonal:
#MarkDown(
"""#### Usage

	math.Matrix.diagonal(n, value = 1.0)

#### Description

Computes a diagonal matrix.

#### Arguments

* `n` - an integer. The returned matrix will have dimension `(n, n)`.
* `value` - the value to place in the diagonal. The matrix will take its type from this value.

""")
	fun
    (filters.IsVector(v))
        {
        let n = size(v);

        Matrix(
            Vector.range(
                n * n,
                fun(ix) { 
                    if (ix % n == ix / n)
                        v[ix % n]
                    else {
                        try {
                            return v.homogeneousElementType(0)
                            }
                        catch (...) {
                            return 0.0;
                            }
                        }
                    }
                ),
            (n, n)
            )                     
        }
    (n, filters.IsVector(v))
        {
        if (size(v) != n)
            throw "size mismatch in arguments: needed size " + String(n) + ", got " + String(size(v));

        diagonal(v)
        }
    (n, value = 1.0) 
		{
		Matrix(
			Vector.range(n*n,
				fun(ix) {
					if (ix % n == ix / n)
						value
					else
						value * 0.0
					}
				),
			(n,n)
			)
		}
		;

	static uniform:
#Markdown(
"""#### Usage

	math.Matrix.uniform(dim, value = 0.0)

#### Description

Computes a matrix with a single given value in every entry.
	
#### Arguments

* `dim` - the dimensions of the desired matrix
* `value` - the value to place in each entry of the matrix.

""")
	fun(dim, value = 0.0) 
		{
		createInstance(cls, matrixImpl_: Tensor.uniform(dim, value))
		}
		;

	};



