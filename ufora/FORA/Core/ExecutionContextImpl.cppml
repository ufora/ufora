/***************************************************************************
   Copyright 2015 Ufora Inc.

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
****************************************************************************/
#include "../../core/Platform.hpp"

#include "ExecutionContextImpl.hppml"
#include "ExecutionContextMemoryPool.hppml"
#include "ExecutionContextConfiguration.hppml"
#include "../TypedFora/ABI/BigVectorHandleArraySlotManager.hppml"
#include "../ControlFlowGraph/ControlFlowGraphUtil.hppml"
#include <boost/uuid/uuid_generators.hpp>
#include <boost/uuid/uuid_io.hpp>
#include "../../core/math/RandomHashGenerator.hpp"

#include "../Serialization/SerializedObject.hpp"
#include "../Serialization/ForaValueSerializationStream.hppml"
#include "RefcountPool.hppml"
#include "StackFrame.hpp"
#include "StackFrameAllocator.hpp"
#include "../VectorDataManager/VectorDataManager.hppml"
#include "../VectorDataManager/VectorDataManagerImpl.hppml"
#include "../TypedFora/ABI/VectorHandle.hpp"
#include "../TypedFora/ABI/StackFrameVisitor.hppml"
#include "../../core/cppml/CPPMLPrettyPrinter.hppml"
#include "../../core/threading/ScopedThreadLocalContext.hpp"
#include "../../core/Memory.hpp"
#include "../../core/StringUtil.hpp"
#include "../../core/Logging.hpp"
#include "../../core/Clock.hpp"
#include "../../core/SymbolExport.hpp"
#include "../../core/Memory.hpp"
#include "../../core/PolymorphicSharedPtrBinder.hpp"
#include "../VectorDataManager/PageRefcountTracker.hppml"
#include "../../cumulus/SystemwidePageRefcountTracker.hppml"
#include "ValueDeepcopier.hppml"
#include "ExecutionContextThreadState.hppml"
#include "ExecutionContextThreadStateTree.hppml"
#include "RefcountPool.hppml"

#include "PausedComputationTree.hppml"
#include "CreatePausedComputationStackFrameVisitor.hppml"
#include "ExtractCodeLocationsStackFrameVisitor.hppml"
#include "CopyDataOutOfVectorPages.hppml"
#include "ExecutionContextThreadValueUpdater.hppml"
#include "ValidateVectorRefcountsValueUpdater.hppml"
#include "PageUnpagedVectorsValueUpdater.hppml"
#include "StackValueModifyingStackFrameVisitor.hppml"
#include "PrintStacktraceStackFrameVisitor.hppml"
#include "RefcountPoolAddingStackFrameVisitor.hppml"
#include "DestroyingStackFrameVisitor.hppml"
#include "../Interpreter/CallFrame.hpp"
#include "../Interpreter/EvalFrame.hpp"
#include "../Interpreter/InterpreterFrame.hppml"
#include "../Runtime.hppml"
#include "../TypedFora/JitCompiler/TypedJumpTarget.hppml"
#include "../TypedFora/TypedForaUtil.hppml"
#include "../TypedFora/ABI/NativeLayoutType.hppml"
#include "../Native/NativeRuntimeContinuationValue.hppml"
#include "../Native/NativeRuntimeCallTarget.hppml"
#include "../TypedFora/ABI/ImplValVisitor.hppml"

using namespace Ufora::threading;
using namespace std;


namespace Fora {
namespace Interpreter {



ExecutionContextImpl::ExecutionContextImpl(
			PolymorphicSharedPtr<VectorDataManager> inVDM,
			uint64_t memoryQuota,
			ExecutionContext* inActualContextPtr
			) :
		mVectorDataManager(inVDM),
		mActualContextPtr(inActualContextPtr),
		mOnCheckGcStatusWithVdm(inVDM->getCallbackScheduler()),
		mConfig(
			new ExecutionContextConfiguration(
				ExecutionContextConfiguration::defaultConfig()
				)
			),
		mCurrentExecutionContextScope(0),
		mRefcountPool(0),
		mBigVectorReferences(
			inVDM,
			this
			),
		mExecutionState(
			this,
			&mRuntimeCallbacks.interruptFlag,
			&mRuntimeCallbacks.interruptCounter
			),
		mIsGarbageCollectingNow(false),
		mBytesAllocatedAfterLastEvent(0),
		mBytesAllocatedFromOSAfterLastEvent(0),
		mIsDestroyed(false),
		mIsMemoryPoolDefragmentDisabled(false),
		mVectorPagingDisabled(false),
		mDoubleVectorStashAllocator(this),
		mCurrentlyExecutingThread(nullptr)
	{
	mInterpreterHistory =
		Runtime::getRuntime().getInterpreterTraceHandler()->allocateInterpreterHistory(mConfig);

	mMemoryPool.reset(
		new ExecutionContextMemoryPool(
			mActualContextPtr,
			mVectorDataManager->getMemoryManager()
			)
		);

	mRefcountPool = new RefcountPool(mMemoryPool.get());

	lassert(mVectorDataManager);

	mRuntimeCallbacks.resetNativeRuntimeState();

	if (SHOULD_LOG_DEBUG())
        LOG_DEBUG << "creating an EC. total mem = "
			<< Ufora::Memory::getTotalBytesAllocated() / 1024 / 1024.0
			<< ". Total allocated from OS = "
			<< Ufora::Memory::getTotalBytesRequestedFromOS() / 1024 / 1024.0
			;
	}

void ExecutionContextImpl::polymorphicSharedPtrBaseInitialized()
	{
	mVectorDataManager->mImpl->registerExecutionContext(this);
	}

void ExecutionContextImpl::disableMemoryPoolDefragment()
	{
	mIsMemoryPoolDefragmentDisabled = true;
	}

NativeRuntimeCallbacks& ExecutionContextImpl::getRuntimeCallbacks()
	{
	return mRuntimeCallbacks;
	}

VectorDataManager& ExecutionContextImpl::getVDM()
	{
	return *mVectorDataManager;
	}

void ExecutionContextImpl::initialize()
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	initialize_();
	}

void ExecutionContextImpl::initialize_()
	{
	mThreadState.reset(new ExecutionContextThreadStateTree(this));
	}

ExecutionContextImpl::~ExecutionContextImpl()
	{
	}

void ExecutionContextImpl::enableVectorPaging()
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	mVectorPagingDisabled = false;
	}

void ExecutionContextImpl::disableVectorPaging()
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	mVectorPagingDisabled = true;
	}

void ExecutionContextImpl::destroySelf()
	{
	mExecutionState.markDestroyed();

	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	mIsDestroyed = true;

	try {
		teardown_(false, true);
		}
	catch(std::exception& e)
		{
		LOG_CRITICAL << "exception while tearing down"
			<< " an ExecutionContextImpl:\n" << e.what();
		}

	try {
		mVectorDataManager->mImpl->unregisterExecutionContext(this, mMemoryPool.get());
		}
	catch(std::exception& e)
		{
		LOG_CRITICAL << "exception while unregistering "
				<< " an ExecutionContextImpl:\n" << e.what();
		}

	delete mRefcountPool;
	mMemoryPool.reset();

	if (SHOULD_LOG_DEBUG())
		LOG_DEBUG << "destroying an EC. total mem = "
			<< Ufora::Memory::getTotalBytesAllocated() / 1024 / 1024.0
			<< ". Total allocated from OS = "
			<< Ufora::Memory::getTotalBytesRequestedFromOS() / 1024 / 1024.0
			;
	}

boost::shared_ptr<ExecutionContextConfiguration> ExecutionContextImpl::getConfiguration() const
	{
	return mConfig;
	}

void ExecutionContextImpl::setOnPageCreated(boost::function1<void, Fora::PageId> function)
	{
	mOnPageCreated = function;
	}

PausedComputationTreeStats ExecutionContextImpl::getStats() const
	{
	if (!mThreadState)
		return PausedComputationTreeStats();
	
	return mThreadState->treeStats();
	}

void ExecutionContextImpl::onPageCreated(Fora::PageId page)
	{
	if (mOnPageCreated)
		mOnPageCreated(page);
	}

ExecutionContext* ExecutionContextImpl::currentExecutionContext()
	{
	return ScopedThreadLocalContext<ExecutionContext>::getPtr();
	}

VectorDataManager& ExecutionContextImpl::currentVDM()
	{
	ExecutionContext* context = currentExecutionContext();
	lassert(context);

	return context->getVDM();
	}

bool ExecutionContextImpl::isExecuting() const
	{
	return mExecutionState.isExecuting();
	}

bool ExecutionContextImpl::isGarbageCollecting() const
	{
	return mIsGarbageCollectingNow;
	}

bool ExecutionContextImpl::acquireMemoryPoolLocksAndMarkExecuting_()
	{
	if (mMemoryPool->isExecuting())
		return true;

	long tries = 0;
	double delay = 0.0000001;

	bool hasAcquiredExecutionLock = false;

	while (!hasAcquiredExecutionLock)
		{
		if (mMemoryPool->needsCleanBeforeExecuting())
			copyValuesOutOfVectorPages_(false, true);

		if (!mMemoryPool->acquireLocksOnPagelets())
			{
			tries++;
			sleepSeconds(delay);
			delay *= 2;

			if (delay > 0.0001)
				{
				LOG_WARN << "Failed to acquire memory pool locks.";
				return false;
				}
			}
			else
		if (mMemoryPool->beginExecution())
			hasAcquiredExecutionLock = true;
		}

	return true;
	}

void ExecutionContextImpl::placeInEvaluationStateWithoutRenamingMutableVectors(const ImplValContainer& args)
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	teardown_(false, true);

	ValueDeepcopierState state;

	mThreadState->placeInEvaluationState(
		args,
		boost::bind(
			&ExecutionContextImpl::importIntoExecutionContextFromStatePtr_,
			this,
			boost::arg<1>(),
			&state,
			true,
			false
			)
		);

	if (mConfig->agressivelyValidateRefcountsAndPageReachability())
		validateVectorHandleRefcounts_("After placeInEvaluationState", state);
	}


void ExecutionContextImpl::evaluateFunctionPointer(
					const TypedFora::TypedJumpTarget& toCall,
					const ImplValContainer& inArgs
					)
	{
		{
		ExecutionContextMarkExecutingScope lock(mExecutionState);

		initialize_();

		ValueDeepcopierState state;

		ImplValContainer value = importIntoExecutionContext_(inArgs, state);

		if (mConfig->agressivelyValidateRefcountsAndPageReachability())
			validateVectorHandleRefcounts_("After importing values for Evaluation", state);

		if (!mVectorDataManager->isTornDown())
			{
			lassert_dump(
				acquireMemoryPoolLocksAndMarkExecuting_(),
				"we couldn't acquire locks, but we don't have a way to leave behind the "
					"context in a consistent state without running native FORA code."
				);

			mThreadState->evaluateFunctionPointer(toCall, value);
			}
		}

	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	if (mConfig->releaseVectorHandlesImmediatelyAfterExecution())
		copyValuesOutOfVectorPages_(true, true);
	}

void ExecutionContextImpl::addCachecallResult(const ComputationResult& val)
	{
	ExecutionContextMarkExecutingScope lock(mExecutionState);

	lassert(isCacheRequest());
	
	ImplValContainer innerVal;

	@match ComputationResult(val)
		-| Result(inner) ->> { 
			innerVal = inner;  
			}
		-| Exception(inner) ->> { 
			innerVal = inner;
			}
		-| Failure() ->> {
			throwLogicErrorWithStacktrace("Can't resume a computation with a failure: " + 
				prettyPrintString(val)
				);
			}

	ValueDeepcopierState state;

	ImplValContainer imported = importIntoExecutionContext_(innerVal, state);

	mThreadState->addCachecallResult(imported, val.isException());
	}

void ExecutionContextImpl::updateLastEventMemoryLevels_()
	{
	if (mMemoryPool)
		{
		mBytesAllocatedAfterLastEvent = mMemoryPool->totalBytesAllocated();
		mBytesAllocatedFromOSAfterLastEvent = mMemoryPool->totalBytesAllocatedFromOS();
		}
	}

void ExecutionContextImpl::compute()
	{
		{
		ExecutionContextMarkExecutingScope lock(mExecutionState);

		if (mConfig->agressivelyValidateRefcountsAndPageReachability())
			validateVectorHandleRefcounts_("Resuming computation");

		if (!mVectorDataManager->isTornDown() && !(isFinished() || isCacheRequest()))
			{
			if (acquireMemoryPoolLocksAndMarkExecuting_())
				{
				mThreadState->compute();
				}
			}
		
		if (mConfig->agressivelyValidateRefcountsAndPageReachability())
			validateVectorHandleRefcounts_("After computing");
		}

	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	if (mConfig->releaseVectorHandlesImmediatelyAfterExecution())
		{
		pageLargeVectorHandles();
		copyValuesOutOfVectorPages_(true, true);
		}
	}


void ExecutionContextImpl::triggerInternalInterruptAtTime(double timestamp)
	{
	mExecutionState.triggerInternalInterruptAtTime(timestamp);
	}

void ExecutionContextImpl::disableScheduledInternalInterruptTrigger()
	{
	mExecutionState.disableScheduledInternalInterruptTrigger();
	}

void ExecutionContextImpl::interruptAfterCycleCount(sword_t checks)
	{
	mExecutionState.interruptAfterCycleCount(checks);
	}

sword_t ExecutionContextImpl::remainingCycleCount()
	{
	return mExecutionState.remainingCycleCount();
	}

void ExecutionContextImpl::resetInterruptState()
	{
	mExecutionState.resetInterruptState();
	}

bool ExecutionContextImpl::resetInterruptStateIfOnlyTriggeredInternally()
	{
	return mExecutionState.resetInterruptStateIfOnlyTriggeredInternally();
	}

bool ExecutionContextImpl::resetInterruptStateIfOnlyTriggeredInternallyAndNoGcPending()
	{
	return mExecutionState.resetInterruptStateIfOnlyTriggeredInternallyAndNoGcPending();
	}

void ExecutionContextImpl::interrupt()
	{
	mExecutionState.interrupt();
	}

bool ExecutionContextImpl::shouldInterrupt()
	{
	return mExecutionState.isInterrupted();
	}

bool ExecutionContextImpl::isGcScheduled()
	{
	return mExecutionState.isGcScheduled();
	}

bool ExecutionContextImpl::isInterruptTriggerSet()
	{
	return mExecutionState.isInterrupted();
	}

bool ExecutionContextImpl::isGcPending()
	{
	return mExecutionState.isGcPending();
	}

void ExecutionContextImpl::scheduleVdmCheck()
	{
	if (mIsGarbageCollectingNow)
		return;

	mExecutionState.scheduleVdmCheck();
	}

void ExecutionContextImpl::unloadAllVectorHandlesFromPool()
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	copyValuesOutOfVectorPages_(false, true);
	}

std::string ExecutionContextImpl::stateAsString()
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	if (!mThreadState)
		return "<empty>";

	return mThreadState->treeStateToString();
	}

void ExecutionContextImpl::checkGcStatusWithVdm_()
	{
	if (mIsDestroyed)
		{
		LOG_WARN << "avoiding GC on a destroyed ExecutionContextImpl";
		return;
		}

	mOnCheckGcStatusWithVdm.broadcast(curClock());

	if (!mThreadState)
		return;

	mIsGarbageCollectingNow = true;

	double t0 = curClock();

	bool done = false;

	mGcLog
		<< "begin GC pass. memory is " << mMemoryPool->totalBytesAllocated() / 1024 / 1024.0
		<< " MB. "
		<< mMemoryPool->totalBytesAllocatedFromOS() /1024/1024.0 << " from OS."
		<< "\n"
		;

	while (!done)
		{
		bool wantGc = false;
		bool wantPageLargeVectors = false;
		bool wantCopyDataOutOfPages = false;
		bool wantsMemoryPoolDefragment = false;

		mVectorDataManager->mImpl->checkDesiredEcCleanupStatus(
			this,
			wantGc,
			wantPageLargeVectors,
			wantCopyDataOutOfPages,
			wantsMemoryPoolDefragment
			);

		mGcLog
			<< "after " << curClock() - t0 << ": "
			<< "wantGC = " << (wantGc ? "true":"false") << ". "
			<< "wantPageLargeVectors = " << (wantPageLargeVectors ? "true":"false") << ". "
			<< "wantCopyDataOutOfPages = " << (wantCopyDataOutOfPages ? "true":"false") << ". "
			<< "wantsMemoryPoolDefragment = " << (wantsMemoryPoolDefragment ? "true":"false") << ". "
			<< "mVectorPagingDisabled = " << (mVectorPagingDisabled ? "true":"false") << "."
			<< "memory=" << mMemoryPool->totalBytesAllocatedFromOS() / 1024.0 / 1024.0 << " MB from OS. "
			<< "pagelets=" << getExecutionContextMemoryPool()->totalBytesFromOSHeldInPagelets() / 1024 / 1024.0 << " MB."
			<< "\n"
			;

		if (wantGc && !wantPageLargeVectors)
			//pageLargeVectors recycles the refcount pool already
			recycleRefcountPool_();

		if (wantPageLargeVectors)
			pageLargeVectorHandles();

		if (wantCopyDataOutOfPages)
			unloadAllVectorHandlesFromPool();

		if (wantsMemoryPoolDefragment)
			defragmentMemoryUsage_();

		bool shouldLog = (curClock() - t0 > .1 ? true : SHOULD_LOG_DEBUG());

		if (shouldLog)
			{
			if (curClock() - t0 > .1)
				{
				LOG_WARN
					<< "checkGcStatusWithVdm_ cycle took " << curClock() - t0
					<< ". total memory used is "
					<< mMemoryPool->totalBytesAllocated() / 1024 / 1024.0
					<< " MB. total bytes from OS is "
					<< mMemoryPool->totalBytesAllocatedFromOS() / 1024 / 1024.0
					<< " MB.\n"
					<< mThreadState->treeStats()
					;
				}
			else
				{
				LOG_DEBUG
					<< "checkGcStatusWithVdm_ cycle took " << curClock() - t0
					<< ". total memory used is "
					<< mMemoryPool->totalBytesAllocated() / 1024 / 1024.0
					<< " MB. total bytes from OS is "
					<< mMemoryPool->totalBytesAllocatedFromOS() / 1024 / 1024.0
					<< " MB."
					;
				}
			}

		if (wantPageLargeVectors || wantGc)
			updateLastEventMemoryLevels_();

		if (!mVectorDataManager->mImpl->shouldEcCleanupRetry(this))
			done = true;
		}

	mGcLog
		<< "end GC pass. memory is " << mMemoryPool->totalBytesAllocated() / 1024 / 1024.0
		<< " MB. "
		<< mMemoryPool->totalBytesAllocatedFromOS() /1024/1024.0 << " from OS."
		<< ". elapsed = " << curClock() - t0
		<< "\n"
		;

	mTimeElapsed.timeSpentGarbageCollecting() += curClock() - t0;

	mIsGarbageCollectingNow = false;
	}

void ExecutionContextImpl::setMemoryPoolPageSize(size_t newPageSize)
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	mMemoryPoolPageSizeOverride = newPageSize;

	defragmentMemoryUsage_();
	}

void ExecutionContextImpl::resetMemoryPoolPageSize()
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	mMemoryPoolPageSizeOverride = null();

	defragmentMemoryUsage_();
	}

void ExecutionContextImpl::defragmentMemoryUsage_()
	{
	if (mIsMemoryPoolDefragmentDisabled)
		return;

	if (mConfig->agressivelyValidateRefcountsAndPageReachability())
		validateVectorHandleRefcounts_("Before defragmentMemoryUsage");

	if (isEmpty())
		return;

	PausedComputationTree computation;

	double t0 = curClock();

		{
		ValueDeepcopierState state;

		computation = extractPausedComputation(state, true);
		}

	resumePausedComputation(computation);
	}

std::string ExecutionContextImpl::extractCurrentTextStacktrace(long maxBytes)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	std::ostringstream stream;

	PrintStacktraceStackFrameVisitor visitor(stream, false, maxBytes);

	mThreadState->visitStackFramesAndValues(visitor);

	return stream.str();
	}

bool ExecutionContextImpl::pageLargeVectorHandles()
	{
	return pageLargeVectorHandles(
		mVectorDataManager->mImpl->getCurrentLargeVectorHandlePageSize(this)
		);
	}

void ExecutionContextImpl::validateVectorHandleRefcounts(std::string inCallingContext)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	validateVectorHandleRefcounts_(inCallingContext);
	}

void ExecutionContextImpl::validateReachablePages_(std::string msg)
	{
	ValidateVectorRefcountsValueUpdaterState state(
					mVectorDataManager->getMemoryManager(),
					getMemoryPool(),
					"validateReachablePages_",
					mCurrentBigvecSlotIndex,
					false,
					false,
					true
					);

	StackValueModifyingStackFrameVisitor<ValidateVectorRefcountsValueUpdater> visitor(
		state,
		mConfig->agressivelyValidateRefcountsAndPageReachability()
		);

	ValidateVectorRefcountsValueUpdater updater(state);

	mThreadState->visitStackFramesAndValues(visitor);
	}

void ExecutionContextImpl::validateVectorHandleRefcounts_(
										std::string inCallingContext,
										bool assertNoOutsideMemoryPools
										)
	{
	ValueDeepcopierState state;

	validateVectorHandleRefcounts_(inCallingContext, state, assertNoOutsideMemoryPools);
	}

void ExecutionContextImpl::validateVectorHandleRefcounts_(
										std::string inCallingContext,
										ValueDeepcopierState& ioState,
										bool assertNoOutsideMemoryPools,
										bool verbose
										)
	{
	double t0 = curClock();
	bool result = false;

	ValidateVectorRefcountsValueUpdaterState state(
					mVectorDataManager->getMemoryManager(),
					getMemoryPool(),
					inCallingContext,
					mCurrentBigvecSlotIndex,
					verbose,
					assertNoOutsideMemoryPools,
					true
					);

	StackValueModifyingStackFrameVisitor<ValidateVectorRefcountsValueUpdater> visitor(
		state,
		mConfig->agressivelyValidateRefcountsAndPageReachability()
		);

	ValidateVectorRefcountsValueUpdater updater(state);
	updater.visitRefcountPool(*mRefcountPool);

	for (auto it = ioState.mVectors.begin(); it != ioState.mVectors.end(); ++it)
		updater.visitVectorRecordInRefcountPool(it->second);

	for (auto it = ioState.mMutableVectors.begin(); it != ioState.mMutableVectors.end(); ++it)
		lassert_dump(false, "IOU THIS METHOID");
		//updater.visitMutableVectorInRefcountPool(it->second.getRecord());

	mThreadState->visitStackFramesAndValues(visitor);

	try {
		state.validate();
		}
	catch(std::logic_error& e)
		{
		if (verbose)
			throw e;
		else
			validateVectorHandleRefcounts_(inCallingContext, ioState, assertNoOutsideMemoryPools, true);
		}
	}

void ExecutionContextImpl::pageLargeVectorHandles(
							const std::set<TypedFora::Abi::VectorHandle*> &handles
							)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	if (mVectorPagingDisabled)
		return;

	PageUnpagedVectorsValueUpdater::state_type pagerState(
		mMemoryPool.get(),
		&*mVectorDataManager,
		0,
		false
		);

	pagerState.mVectorsToForcePaging = handles;

	ExecutionContextThreadValueUpdater<PageUnpagedVectorsValueUpdater>::state_type
		state(
			mVectorDataManager,
			*mRefcountPool,
			mMemoryPool.get(),
			pagerState
			);

	StackValueModifyingStackFrameVisitor<
			ExecutionContextThreadValueUpdater<
				PageUnpagedVectorsValueUpdater
				>
			>
		visitor(state, false);

	mThreadState->visitStackFramesAndValues(visitor);

	recycleRefcountPool_();

	state.cleanup();
	}



bool ExecutionContextImpl::pageLargeVectorHandles(uword_t inBytecountThreshold)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	if (mVectorPagingDisabled)
		return false;

	double t0 = curClock();
	bool result = false;

	if (mConfig->agressivelyValidateRefcountsAndPageReachability())
		validateVectorHandleRefcounts_("Before pageLargeVectorHandles");

		{
		PageUnpagedVectorsValueUpdater::state_type pagerState(
			mMemoryPool.get(),
			&*mVectorDataManager,
			inBytecountThreshold
			);

		ExecutionContextThreadValueUpdater<PageUnpagedVectorsValueUpdater>::state_type
			state(
				mVectorDataManager,
				*mRefcountPool,
				mMemoryPool.get(),
				pagerState
				);

		StackValueModifyingStackFrameVisitor<
				ExecutionContextThreadValueUpdater<
					PageUnpagedVectorsValueUpdater
					>
				>
			visitor(
				state,
				mConfig->agressivelyValidateRefcountsAndPageReachability()
				);

		mThreadState->visitStackFramesAndValues(visitor);

		recycleRefcountPool_();

		if (curClock() - t0 > .1)
			LOG_WARN
				<< "pageLargeVectorHandles took " << curClock() - t0
				<< ". visited "
				<< state.mVectorHandlesVisited.size()
				<< " handles."
				;

		state.cleanup();

		result = pagerState.mPagedVectorCount;
		}

	if (mConfig->agressivelyValidateRefcountsAndPageReachability())
		validateVectorHandleRefcounts_("After pageLargeVectorHandles");

	return result;
	}

void ExecutionContextImpl::dumpCurrentTextStacktraceToLogWarn()
	{
	LOG_WARN << extractCurrentTextStacktrace(1024*1024);
	}

bool ExecutionContextImpl::copyValuesOutOfVectorPages(void)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	return copyValuesOutOfVectorPages_(false, true);
	}

bool ExecutionContextImpl::copyValuesOutOfVectorPages_(bool releaseBigvecSlot, bool cleanMemoryPool)
	{
	if (mConfig->agressivelyValidateRefcountsAndPageReachability())
		validateVectorHandleRefcounts_("Before copyValuesOutOfVectorPages");

	long result = 0;
		{
		CopyDataOutOfVectorPages::state_type copierState(mMemoryPool.get(), &*mVectorDataManager);

		ExecutionContextThreadValueUpdater<CopyDataOutOfVectorPages>::state_type
			state(
				mVectorDataManager,
				*mRefcountPool,
				mMemoryPool.get(),
				copierState
				);

		StackValueModifyingStackFrameVisitor<
			ExecutionContextThreadValueUpdater<CopyDataOutOfVectorPages>
			> visitor(state, mConfig->agressivelyValidateRefcountsAndPageReachability());

		double t0 = curClock();

		mThreadState->visitStackFramesAndValues(visitor);

		if (curClock() - t0 > .05)
			LOG_WARN << "copyValuesOutOfVectorPages took " << curClock() - t0;

		state.cleanup();

		result = copierState.mTotalValuesCopied;
		}

	unmapAllBigVectorArrayHandles();

	if (cleanMemoryPool)
		{
		//always do this before recycling the refcount pool
		mDoubleVectorStashAllocator.clear();

		recycleRefcountPool_();

		mMemoryPool->memoryPoolIsClean();
		}

	if (mCurrentBigvecSlotIndex && releaseBigvecSlot)
		{
		TypedFora::Abi::BigVectorHandleArraySlotManager::singleton()
			.release(*mCurrentBigvecSlotIndex);
		mCurrentBigvecSlotIndex = null();
		mRuntimeCallbacks.bigVectorSlotIndex = -1;
		}

	if (releaseBigvecSlot && cleanMemoryPool)
		{
		for (auto id: mBigVectorReferences.flushPendingDecrements())
			mVectorDataManager->getPageRefcountTracker()->bigVectorDecreffed(id);
		}

	if (mConfig->agressivelyValidateRefcountsAndPageReachability())
		validateVectorHandleRefcounts_("After copyValuesOutOfVectorPages", true);

	return result > 0;
	}

ImplValContainer ExecutionContextImpl::exportImplval_(
			ImplVal value,
			ValueDeepcopierState& ioState
			)
	{
	return exportFromExecutionContext_(
				ImplValContainer(value),
				ioState
				);
	}

void ExecutionContextImpl::teardown(bool assertEmpty)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	teardown_(assertEmpty, true);
	}

void ExecutionContextImpl::teardown_(bool assertEmpty, bool tearDownVectorPageSlots)
	{
	mCurrentVectorHash = null();

	mThreadState.reset();

	//always do this before recycling the refcount pool
	mDoubleVectorStashAllocator.clear();

	mRefcountPool->clear();

	mGcLog.clear();

	mInterpreterHistory->clear();

	unmapAllBigVectorArrayHandles();

	mMemoryPool->memoryPoolIsClean();

	if (mCurrentBigvecSlotIndex)
		{
		TypedFora::Abi::BigVectorHandleArraySlotManager::singleton()
			.release(*mCurrentBigvecSlotIndex);
		mCurrentBigvecSlotIndex = null();
		mRuntimeCallbacks.bigVectorSlotIndex = -1;
		}

	delete mRefcountPool;

	mMemoryPool.reset(
		new ExecutionContextMemoryPool(
			mActualContextPtr,
			mVectorDataManager->getMemoryManager()
			)
		);

	if (mMemoryPoolPageSizeOverride)
		mMemoryPool->setPageSize(*mMemoryPoolPageSizeOverride);

	mRefcountPool = new RefcountPool(mMemoryPool.get());

	if (mMemoryPool->totalBytesAllocated() != 0)
		{
		LOG_ERROR
			<< "ExecutionContextImpl still using "
			<< mMemoryPool->totalBytesAllocated() / 1024.0 / 1024.0
			<< " MB of data allocated."
			;

		if (assertEmpty)
			lassert(false);
		}

	if (tearDownVectorPageSlots)
		{
		for (auto id: mBigVectorReferences.flushPendingDecrements())
			mVectorDataManager->getPageRefcountTracker()->bigVectorDecreffed(id);

		mBigVectorReferences.teardown();
		}

	initialize_();
	}

bool ExecutionContextImpl::isEmpty(void) const
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	if (!mThreadState)
		return true;

	return mThreadState->isEmpty();
	}

bool ExecutionContextImpl::isError(void) const
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	if (!mThreadState)
		return false;
	
	auto leftmost = mThreadState->getLeftmostThread();
	if (!leftmost)
		return false;
	return leftmost->isError();
	}

bool ExecutionContextImpl::isInterrupted(void) const
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);
	if (!mThreadState)
		return false;

	auto leftmost = mThreadState->getLeftmostThread();
	if (!leftmost)
		return false;
	return leftmost->isInterrupted();
	}

bool ExecutionContextImpl::isVectorLoad(void) const
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	if (!mThreadState)
		return false;

	lassert(!mThreadState->isEmpty());

	auto leftmost = mThreadState->getLeftmostThread();
	if (!leftmost)
		return false;
	return leftmost->isVectorLoad();
	}

Fora::BigVectorSlice ExecutionContextImpl::getVectorLoad(void) const
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	lassert(isVectorLoad());

	return mThreadState->getLeftmostThread()->getVectorLoad();
	}

bool ExecutionContextImpl::isCacheRequest(void) const
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	if (!mThreadState)
		return false;

	auto leftmost = mThreadState->getLeftmostThread();
	if (!leftmost)
		return false;
	
	return leftmost->isCacheRequest() && mThreadState->treeStats().countOfActiveThreads() == 0;
	}

ImplValContainer ExecutionContextImpl::getCacheRequest(void)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	lassert(isCacheRequest());

	ValueDeepcopierState state;

	return exportFromExecutionContext_(
			ImplValContainer(mThreadState->getLeftmostThread()->getCacheRequestTuple()),
			state
			);
	}

bool ExecutionContextImpl::isFinished(void) const
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	if (!mThreadState)
		return false;

	return mThreadState->isFinished();
	}

ComputationResult ExecutionContextImpl::getFinishedResult(void)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	lassert(isFinished());

	if (!mThreadState->getErrorState().isNone())
		return ComputationResult::Failure(mThreadState->getErrorState());

	pageLargeVectorHandles();

	ValueDeepcopierState state;

	ImplValContainer exportedValue = exportFromExecutionContext_(
		ImplValContainer(mThreadState->getResult()),
		state
		);

	if (mThreadState->isExceptionResult())
		return ComputationResult::Exception(exportedValue, ImplValContainer());

	return ComputationResult::Result(exportedValue, ImplValContainer());
	}

void ExecutionContextImpl::setFinishedResult(const ComputationResult& result)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	ImmutableTreeSet<Fora::BigVectorId> referenced = getReferencedBigVectors();

	//keep all of our living page references alive until after the import is finished
	for (long k = 0; k < referenced.size();k++)
		incrementBigVectorRefcount(referenced[k]);

	teardown_(true, false);

	if (result.isFailure())
		{
		lassert(!result.getFailure().error().isNone());
		mThreadState->setErrorState(result.getFailure().error());

		//keep all of our living page references alive until after the import is finished
		for (long k = 0; k < referenced.size();k++)
			decrementBigVectorRefcount(referenced[k]);

		return;
		}
	else
		mThreadState->setErrorState(ErrorState::None());

	ImplValContainer toPlace;
	bool isException;

	@match ComputationResult(result)
		-| Result(val) ->> {
			toPlace = val;
			isException = false;
			}
		-| Exception(val) ->> {
			toPlace = val;
			isException = true;
			}

		{
		ImplValContainer finalValue;

			{
			ValueDeepcopierState state;

			finalValue = importIntoExecutionContext_(
				toPlace,
				state
				);
			}

		mThreadState->setResult(finalValue, isException);
		}

	//keep all of our living page references alive until after the import is finished
	for (long k = 0; k < referenced.size();k++)
		decrementBigVectorRefcount(referenced[k]);

	if (mConfig->agressivelyValidateRefcountsAndPageReachability())
		validateVectorHandleRefcounts_("Inside setFinishedResult");
	}

void ExecutionContextImpl::lockAndExecute(boost::function<void ()> func)
	{
		{
		ExecutionContextMarkExecutingScope scope(mExecutionState);

		func();
		}

	copyValuesOutOfVectorPages_(true, true);
	}

void ExecutionContextImpl::lockAndSetFinishedResult(boost::function<Fora::Interpreter::ComputationResult ()> func)
	{
		{
		ExecutionContextMarkExecutingScope scope(mExecutionState);

		@match ComputationResult(func())
			-| Result(val, log) ->> {
				mThreadState->setResult(val, false);
				}
			-| Exception(val, log) ->> {
				mThreadState->setResult(val, true);
				}
		}
		
	copyValuesOutOfVectorPages_(true, true);
	}

void ExecutionContextImpl::recycleRefcountPool_()
	{
	RefcountPool* newRefcountPool = new RefcountPool(mMemoryPool.get());

	RefcountPoolAddingStackFrameVisitor visitor(*newRefcountPool);

	mThreadState->visitStackFramesAndValues(visitor);

	setRefcountPool_(newRefcountPool);
	}

TimeElapsed ExecutionContextImpl::getTotalTimeElapsed() const
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	TimeElapsed res = mTimeElapsed;

	if (mThreadState)
		res = res + mThreadState->getTotalTimeElapsed();

	return res;
	}

RefcountPool* ExecutionContextImpl::getRefcountPool(void)
	{
	return mRefcountPool;
	}

void ExecutionContextImpl::setRefcountPool_(RefcountPool* inPool)
	{
	mRefcountPool->clear();

	delete mRefcountPool;

	mRefcountPool = inPool;
	}

MemoryPool* ExecutionContextImpl::getMemoryPool(void)
	{
	return mMemoryPool.get();
	}

boost::shared_ptr<ExecutionContextMemoryPool> ExecutionContextImpl::getExecutionContextMemoryPool(void)
	{
	return mMemoryPool;
	}

void ExecutionContextImpl::memoryAllocationFailed(size_t desiredBytes, size_t allocatedBytes)
	{
	boost::uuids::uuid uuid = boost::uuids::random_generator()();

	LOG_ERROR << "ExecutionContextImpl " << (void*)this << " ran out of memory "
		<< uuid << ", failed allocating " << desiredBytes / 1024 / 1024.0
		<< " MB on top of "
		<< allocatedBytes / 1024 / 1024.0
		<< ". ECMP holding "
		<< getExecutionContextMemoryPool()->totalBytesFromOSHeldInPagelets() / 1024 / 1024.0
		<< " MB of pagelets "
		<< " with max of " << mVectorDataManager->getMemoryManager()->getMaxBytesPerPool()
		<< " at\n"
		<< Ufora::indent(Ufora::debug::StackTrace::getStringTrace())
		<< ". Total bytes used = "
		<< Ufora::Memory::getTotalBytesAllocated() / 1024 / 1024.0 << " MB"
		<< ". Total bytes allocated from OS = "
		<< Ufora::Memory::getTotalBytesRequestedFromOS() / 1024 / 1024.0 << " MB"
		<< ". VDMM using " << mVectorDataManager->getMemoryManager()
				->totalBytesUsedSingleCountingPagelets() / 1024 / 1024.0 << " MB"
		<< ". VDMM ECs+Pagelets using "
		<< mVectorDataManager->getMemoryManager()
				->totalBytesUsedByExecutionContextsIncludingPagelets() / 1024 / 1024.0 << " MB"
		<< "\n\nGC log = \n" << mGcLog.str()
		;

	mCurrentlyExecutingThread->setErrorState(
		ErrorState::MemoryQuotaExceeded(
			uuid,
			desiredBytes,
			allocatedBytes
			)
		);

	interrupt();
	}

long ExecutionContextImpl::incrementBigVectorRefcount(Fora::BigVectorId inBigVectorId)
	{
	if (inBigVectorId.size() == 0)
		return 0;

	long refcount = mBigVectorReferences.incrementBigVectorRefcount(inBigVectorId);

	if (refcount == 1)
		mVectorDataManager->getPageRefcountTracker()->bigVectorIncreffed(inBigVectorId);

	return refcount;
	}

long ExecutionContextImpl::decrementBigVectorRefcount(Fora::BigVectorId inBigVectorId)
	{
	if (inBigVectorId.size() == 0)
		return 0;

	long refcount = mBigVectorReferences.decrementBigVectorRefcount(inBigVectorId);

	if (refcount == 0)
		mVectorDataManager->getPageRefcountTracker()->bigVectorDecreffed(inBigVectorId);

	return refcount;
	}

ImmutableTreeSet<Fora::BigVectorId> ExecutionContextImpl::getReferencedBigVectors()
	{
	return mBigVectorReferences.getReferencedBigVectors();
	}


ImplValContainer	ExecutionContextImpl::importIntoExecutionContext(
						const ImplValContainer& container,
						ValueDeepcopierState& ioState
						)
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	return importIntoExecutionContext_(container, ioState);
	}

ImplValContainer	ExecutionContextImpl::exportFromExecutionContext(
						const ImplValContainer& container,
						ValueDeepcopierState& ioState
						) const
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	return exportFromExecutionContext_(container, ioState);
	}

ImplValContainer	ExecutionContextImpl::importIntoExecutionContext_(
						const ImplValContainer& container,
						ValueDeepcopierState& ioState,
						bool renameMutableVectors
						)
	{
	ValueDeepcopier extractor(ioState, renameMutableVectors, getMemoryPool(), true, false);

	return extractor.duplicate(container);
	}

void ExecutionContextImpl::executionIsStarting_()
	{
	//we only allow bigvector decrements to occur when we are computing. This
	//ensures that clients of the ExecutionContext don't see random GC activity
	//(at the bigvec level) outside of computation events.
	enableVectorDecrements();

	mVectorDataManager->mImpl->executionIsStarting(this);

	if (!mCurrentBigvecSlotIndex)
		{
		double t0 = curClock();

		mCurrentBigvecSlotIndex =
			TypedFora::Abi::BigVectorHandleArraySlotManager::singleton().acquire();

		if (curClock() - t0 > 0.001)
			LOG_WARN << "Spent " << curClock() - t0 << " waiting for a bigvec slot.";

		mRuntimeCallbacks.bigVectorSlotIndex = *mCurrentBigvecSlotIndex;
		}
	}

void ExecutionContextImpl::executionIsStopping_()
	{
	if (mMemoryPool->isExecuting())
		mMemoryPool->endExecution();

	mVectorDataManager->mImpl->executionIsStopping(this);

	disableVectorDecrements();
	}

void ExecutionContextImpl::enableVectorDecrements()
	{
	ImmutableTreeSet<Fora::BigVectorId> dropped =
		mBigVectorReferences.enableVectorDecrements();

	for (auto id: dropped)
		mVectorDataManager->getPageRefcountTracker()->bigVectorDecreffed(id);
	}

void ExecutionContextImpl::disableVectorDecrements()
	{
	mBigVectorReferences.disableVectorDecrements();
	}

ImplValContainer	ExecutionContextImpl::exportFromExecutionContext_(
						const ImplValContainer& container,
						ValueDeepcopierState& ioState
						) const
	{
	ValueDeepcopier extractor(
		ioState,
		false,
		MemoryPool::getFreeStorePool(),
		false,
		false
		);

	return extractor.duplicate(container);
	}

void ExecutionContextImpl::placeInEvaluationState(const ImplValContainer& args)
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	teardown_(false, true);

	ValueDeepcopierState state;

	mExecutionState.resetInterruptState();

	mThreadState->placeInEvaluationState(
		args,
		boost::bind(
			&ExecutionContextImpl::importIntoExecutionContextFromStatePtr_,
			this,
			boost::arg<1>(),
			&state,
			true,
			true
			)
		);

	if (mConfig->agressivelyValidateRefcountsAndPageReachability())
		validateVectorHandleRefcounts_("After placeInEvaluationState", state);
	}


ImmutableTreeVector<pair<ForaStackTrace, Fora::Interpreter::StackframeMetadata> >
		ExecutionContextImpl::extractStacktrace(bool inExportValues)
	{
	return emptyTreeVec();
	}

PausedComputationTree ExecutionContextImpl::extractPausedComputation(
									ValueDeepcopierState& state, 
									bool exportImplvals
									)
	{
	if (!mThreadState)
		return PausedComputationTree();

	pageLargeVectorHandles();

	return mThreadState->extractPausedComputationTree(
		boost::function1<ImplValContainer,ImplValContainer>(
			[&](ImplValContainer ivc) {
				if (exportImplvals)
					return exportFromExecutionContext_(ivc, state);
				else
					return ivc;
			})
		);
	}

PausedComputationTree ExecutionContextImpl::extractPausedComputation()
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	ValueDeepcopierState state;

	return extractPausedComputation(state, true);
	}


void ExecutionContextImpl::resumePausedComputation(const PausedComputationTree& computation)
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	ValueDeepcopierState state;

	resumePausedComputation(state, computation, true);
	}

void ExecutionContextImpl::resumePausedComputation(
									ValueDeepcopierState& state,
									const PausedComputationTree& computation,
									bool importImplvals
									)
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	ImmutableTreeSet<Fora::BigVectorId> referenced = getReferencedBigVectors();

	//keep all of our living page references alive until after the import is finished
	for (long k = 0; k < referenced.size();k++)
		incrementBigVectorRefcount(referenced[k]);

	if (importImplvals)
		teardown_(false, false);
	else
		initialize_();

	mThreadState->placeInEvaluationState(
		computation,
		boost::bind(
			&ExecutionContextImpl::importIntoExecutionContextFromStatePtr_,
			this,
			boost::arg<1>(),
			&state,
			importImplvals,
			false
			)
		);

	mExecutionState.resetInterruptState();

	for (long k = 0; k < referenced.size();k++)
		decrementBigVectorRefcount(referenced[k]);

	if (mConfig->agressivelyValidateRefcountsAndPageReachability())
		validateVectorHandleRefcounts_("After placeInEvaluationState", state);
	}

void ExecutionContextImpl::serialize(Fora::ForaValueSerializationStream& stream)
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	if (mConfig->agressivelyValidateRefcountsAndPageReachability())
		validateVectorHandleRefcounts_("Before serializing");

	copyValuesOutOfVectorPages();

	stream.serialize(*getConfiguration());
	stream.serialize(mTimeElapsed);
	stream.serialize(mBigVectorReferences.getPendingVectorDecrements());

	if (isEmpty())
		{
		stream.serialize((char)0);
		}
		else
		{
		stream.serialize((char)1);
		ValueDeepcopierState state;
		stream.serialize(extractPausedComputation(state, true));
		}
	}

void	ExecutionContextImpl::deserialize(Fora::ForaValueDeserializationStream& stream)
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	teardown_(false, true);

	stream.deserialize(*getConfiguration());
	stream.deserialize(mTimeElapsed);
	
	//get a list of bigvec ids that need to be incremented. These
	//are bigvecs that had been decreffed outside of the compute loop
	//and need to be kept alive until we next compute.
	ImmutableTreeSet<Fora::BigVectorId> pendingBigvecDecrefs;
	stream.deserialize(pendingBigvecDecrefs);
	for (auto bigvec: pendingBigvecDecrefs)
		{
		incrementBigVectorRefcount(bigvec);
		decrementBigVectorRefcount(bigvec);
		}

	char hasPausedComputation;
	stream.deserialize(hasPausedComputation);

	if (hasPausedComputation)
		{
		PausedComputationTree computation;
		stream.deserialize(computation);

		ValueDeepcopierState state;
		resumePausedComputation(state, computation, true);

		if (mConfig->agressivelyValidateRefcountsAndPageReachability())
			validateVectorHandleRefcounts_("After deserialization", state);
		}
	}

hash_type ExecutionContextImpl::newVectorHash()
	{
	if (!mCurrentVectorHash)
		mCurrentVectorHash = mVectorDataManager->getMemoryManager()->newVectorHash();

	mCurrentVectorHash = *mCurrentVectorHash + hash_type(1);

	return *mCurrentVectorHash;
	}

void ExecutionContextImpl::blockedOnMemoryAllocation()
	{
	mVectorDataManager->mImpl->executionContextBlockedOnMemoryAllocation(this);
	}

void ExecutionContextImpl::unblockedOnMemoryAllocation()
	{
	mVectorDataManager->mImpl->executionContextUnblockedOnMemoryAllocation(this);
	}

pair<uint64_t, uint64_t> ExecutionContextImpl::getMemoryUsageAtLastEvent()
	{
	return make_pair(mBytesAllocatedAfterLastEvent, mBytesAllocatedFromOSAfterLastEvent);
	}

pair<uint64_t, uint64_t> ExecutionContextImpl::getCurrentMemoryUsage()
	{
	ExecutionContextInterruptAndLockScope lock(mExecutionState);

	return make_pair(
		mMemoryPool->totalBytesAllocated(),
		mMemoryPool->totalBytesAllocatedFromOS()
		);
	}

bool ExecutionContextImpl::wasLastInterruptTriggeredExternally()
	{
	return mExecutionState.interruptWasExternallyTriggered();
	}

void ExecutionContextImpl::visitStackFramesAndValues(TypedFora::Abi::StackFrameVisitor& visitor)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	if (mThreadState)
		mThreadState->visitStackFramesAndValues(visitor);
	}
Nullable<long> ExecutionContextImpl::getCurrentBigvecSlotIndex() const
	{
	return mCurrentBigvecSlotIndex;
	}

void ExecutionContextImpl::bigVectorArrayHandleMapped(TypedFora::Abi::VectorHandle* ptr)
	{
	mMappedBigVectorHandles.insert(ptr);
	}

void ExecutionContextImpl::unmapAllBigVectorArrayHandles()
	{
	if (!mMappedBigVectorHandles.size())
		return;

	lassert(mCurrentBigvecSlotIndex);

	for (auto handle: mMappedBigVectorHandles)
		handle->unmapBigVectorSlot(*mCurrentBigvecSlotIndex);

	mMappedBigVectorHandles.clear();
	}

void ExecutionContextImpl::unreportAllSlots()
	{
	lassert(mCurrentBigvecSlotIndex);

	for (auto handle: mMappedBigVectorHandles)
		handle->setSlotToStatusUnreported(*mCurrentBigvecSlotIndex);
	}

void ExecutionContextImpl::reportPageReferenced(Fora::PageId pageId)
	{
	lassert(mCurrentlyExecutingThread);
	
	mCurrentlyExecutingThread->pageUsed(pageId);
	}

void ExecutionContextImpl::observeLoadOfVectorPages(const ImmutableTreeSet<Fora::PageId>& pages)
	{
	if (!pages.size())
		return;

	if (mCurrentlyExecutingThread)
		for (auto pageId: pages)
			mCurrentlyExecutingThread->pageUsed(pageId);
	}

void ExecutionContextImpl::onDestroyVectorHandle(TypedFora::Abi::VectorHandle* handle)
	{
	if (mMappedBigVectorHandles.find(handle) != mMappedBigVectorHandles.end())
		{
		mMappedBigVectorHandles.erase(handle);
		handle->unmapBigVectorSlot(*mCurrentBigvecSlotIndex);
		}
	}

void ExecutionContextImpl::setBigvectorSlotForTesting()
	{
	mCurrentBigvecSlotIndex =
		TypedFora::Abi::BigVectorHandleArraySlotManager::singleton().acquire();
	mRuntimeCallbacks.bigVectorSlotIndex = *mCurrentBigvecSlotIndex;
	}

void ExecutionContextImpl::extractPagesTouched(std::set<Fora::PageId>& outPages)
	{
	outPages.clear();
	std::swap(outPages, mPagesTouched);
	}

void ExecutionContextImpl::pageTouched(Fora::PageId inPage)
	{
	mPagesTouched.insert(inPage);
	}

ImmutableTreeVector<PausedComputationTreeSplit> 
			ExecutionContextImpl::splitComputation(bool disableVectorPagingIfSplit, double minSecondsElapsed)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	ValueDeepcopierState state;

	auto res = mThreadState->splitComputation(
				[&](ImplValContainer ivc) {
					return exportFromExecutionContext_(ivc, state);
					},
				minSecondsElapsed
				);

	if (res.size() && disableVectorPagingIfSplit)
		disableVectorPaging();

	return res;
	}

void ExecutionContextImpl::absorbSplitResult(
		hash_type computationHash,
		const ComputationResult& result,
		TimeElapsed totalTimeElapsed
		)
	{
	ExecutionContextInterruptAndLockScope scope(mExecutionState);

	ValueDeepcopierState state;

	@match ComputationResult(result)
		-| Result(ivc) ->> {
			ImplValContainer imported = importIntoExecutionContext_(ivc, state);

			mThreadState->absorbSplitResult(computationHash, imported, false, totalTimeElapsed);
			}
		-| Exception(ivc) ->> {
			ImplValContainer imported = importIntoExecutionContext_(ivc, state);

			mThreadState->absorbSplitResult(computationHash, imported, true, totalTimeElapsed);
			}
		-| Failure(errorState) ->> {
			mThreadState->setErrorState(errorState);
			}
	}

};
}

